{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mIJd6b6pbsk"
      },
      "source": [
        "# First, let us set up a few dependencies\n",
        "\n",
        "Don't forget to switch to a GPU-enabled colab runtime!\n",
        "\n",
        "```\n",
        "Runtime -> Change Runtime Type -> GPU\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E2APl4pnbAa"
      },
      "source": [
        "import os\n",
        "import contextlib\n",
        "@contextlib.contextmanager\n",
        "def directory(name):\n",
        "  ret = os.getcwd()\n",
        "  os.chdir(name)\n",
        "  yield None\n",
        "  os.chdir(ret)\n",
        "\n",
        "import subprocess\n",
        "def run(input, exception_on_failure=False):\n",
        "  try:\n",
        "    program_output = subprocess.check_output(f\"{input}\", shell=True, universal_newlines=True, stderr=subprocess.STDOUT)\n",
        "  except Exception as e:\n",
        "    if exception_on_failure:\n",
        "      raise e\n",
        "    program_output = e.output\n",
        "\n",
        "    return program_output\n",
        "def prun(input, exception_on_failure=False):\n",
        "  x = run(input, exception_on_failure)\n",
        "  print(x)\n",
        "  return x"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6gJLjcipgNw"
      },
      "source": [
        "# This mounts your google drive to this notebook. You might have to change the path to fit with your dataset folder inside your drive.\n",
        "\n",
        "Read the instruction output by the cell bellow carefully!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a temporary workspace\n",
        "import tempfile\n",
        "\n",
        "\n",
        "SESSION_WORKSPACE = tempfile.mkdtemp()\n",
        "print(f\"Session workspace created at: {SESSION_WORKSPACE}\")"
      ],
      "metadata": {
        "id": "shRmyOAbatwZ",
        "outputId": "3cf10e94-b0bb-4b92-86e8-bca010b40c4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Session workspace created at: /tmp/tmpzlhfafkp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -a \"/content/drive/My Drive/\"\n"
      ],
      "metadata": {
        "id": "RAmdV6AdwadV",
        "outputId": "b647b584-1102-49d2-f4ea-0eae427588a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/content/drive/My Drive/': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ],
      "metadata": {
        "id": "k66ScjdC0SlU",
        "outputId": "b8546a5c-1c4b-4daf-8c58-5d094e94056b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "DRIVE_PATH = \"/content/drive/My Drive\""
      ],
      "metadata": {
        "id": "Iod0c4KF_Vxo",
        "outputId": "1b4d8676-7af7-4d10-a92b-a92e483c10e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip the dataset\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "\n",
        "DATASET_DIR_NAME = \"duckietown_object_detection_dataset\"\n",
        "DATASET_ZIP_NAME = f\"{DATASET_DIR_NAME}.zip\"\n",
        "DATASET_DIR_PATH = os.path.join(SESSION_WORKSPACE, DATASET_DIR_NAME)\n",
        "TRAIN_DIR = \"train\"\n",
        "VALIDATION_DIR = \"val\"\n",
        "IMAGES_DIR = \"images\"\n",
        "LABELS_DIR = \"labels\"\n",
        "\n",
        "\n",
        "def show_info(base_path: str):\n",
        "  for l1 in [TRAIN_DIR, VALIDATION_DIR]:\n",
        "    for l2 in [IMAGES_DIR, LABELS_DIR]:\n",
        "      p = os.path.join(base_path, l1, l2)\n",
        "      print(f\"#Files in {l1}/{l2}: {len(os.listdir(p))}\")\n",
        "\n",
        "\n",
        "def unzip_dataset():\n",
        "  # check zipped file\n",
        "  zip_path = os.path.join(DRIVE_PATH, DATASET_ZIP_NAME)\n",
        "  assert os.path.exists(zip_path), f\"No zipped dataset found at {zip_path}! Abort!\"\n",
        "\n",
        "  # unzip the data\n",
        "  print(\"Unpacking zipped data...\")\n",
        "  shutil.unpack_archive(zip_path, DATASET_DIR_PATH)\n",
        "  print(f\"Zipped dataset unpacked to {DATASET_DIR_PATH}\")\n",
        "\n",
        "  # show some info\n",
        "  show_info(DATASET_DIR_PATH)\n",
        "\n",
        "\n",
        "unzip_dataset()"
      ],
      "metadata": {
        "id": "qhdlb1osbf_a",
        "outputId": "e67e5fbc-8c19-4d93-cd14-55472b82a2de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unpacking zipped data...\n",
            "Zipped dataset unpacked to /tmp/tmpzlhfafkp/duckietown_object_detection_dataset\n",
            "#Files in train/images: 804\n",
            "#Files in train/labels: 804\n",
            "#Files in val/images: 202\n",
            "#Files in val/labels: 202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change  working directory to the session workspace\n",
        "os.chdir(SESSION_WORKSPACE)\n",
        "print(f\"PWD: {os.getcwd()}\")\n",
        "\n",
        "# install pytorch and torchvision\n",
        "!pip3 install torch torchvision\n",
        "#!pip3 install torch==1.13.0 torchvision==0.14.0"
      ],
      "metadata": {
        "id": "xpWozMbUeFZA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5a6cb48-29b7-40f2-ce29-0e513f751fb3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PWD: /tmp/tmpzlhfafkp\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m108.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc4VMcwmpr84"
      },
      "source": [
        "# Next, we will clone Yolov5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8L68QAeZF9G",
        "outputId": "f4154260-c58e-4f25-9e36-3c9d08f2ba8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!rm -rf ./yolov5\n",
        "!git clone https://github.com/ultralytics/yolov5.git -b v7.0\n",
        "!cd yolov5 && pip3 install -r requirements.txt"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 17372, done.\u001b[K\n",
            "remote: Counting objects: 100% (59/59), done.\u001b[K\n",
            "remote: Compressing objects: 100% (39/39), done.\u001b[K\n",
            "remote: Total 17372 (delta 42), reused 20 (delta 20), pack-reused 17313 (from 3)\u001b[K\n",
            "Receiving objects: 100% (17372/17372), 16.25 MiB | 17.85 MiB/s, done.\n",
            "Resolving deltas: 100% (11910/11910), done.\n",
            "Note: switching to '915bbf294bb74c859f0b41f1c23bc395014ea679'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by switching back to a branch.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -c with the switch command. Example:\n",
            "\n",
            "  git switch -c <new-branch-name>\n",
            "\n",
            "Or undo this operation with:\n",
            "\n",
            "  git switch -\n",
            "\n",
            "Turn off this advice by setting config variable advice.detachedHead to false\n",
            "\n",
            "Requirement already satisfied: gitpython in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (3.1.44)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (7.34.0)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (2.0.2)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (4.11.0.86)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (11.1.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (5.9.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (1.14.1)\n",
            "Collecting thop>=0.1.1 (from -r requirements.txt (line 15))\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 17)) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 18)) (4.67.1)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 22)) (2.18.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 27)) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 28)) (0.13.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython->-r requirements.txt (line 5)) (4.0.12)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython->-r requirements.txt (line 6)) (75.2.0)\n",
            "Collecting jedi>=0.16 (from ipython->-r requirements.txt (line 6))\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython->-r requirements.txt (line 6)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython->-r requirements.txt (line 6)) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython->-r requirements.txt (line 6)) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython->-r requirements.txt (line 6)) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython->-r requirements.txt (line 6)) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython->-r requirements.txt (line 6)) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython->-r requirements.txt (line 6)) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython->-r requirements.txt (line 6)) (4.9.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 7)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 7)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 7)) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 7)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 7)) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 7)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 7)) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->-r requirements.txt (line 13)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->-r requirements.txt (line 13)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->-r requirements.txt (line 13)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->-r requirements.txt (line 13)) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.7.0->-r requirements.txt (line 16)) (1.3.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (5.29.4)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (3.1.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2025.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython->-r requirements.txt (line 5)) (5.0.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython->-r requirements.txt (line 6)) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython->-r requirements.txt (line 6)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->-r requirements.txt (line 6)) (0.2.13)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->-r requirements.txt (line 22)) (3.0.2)\n",
            "Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jedi, thop\n",
            "Successfully installed jedi-0.19.2 thop-0.1.1.post2209072238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "!ls -la"
      ],
      "metadata": {
        "id": "8FNehsFJkC-c",
        "outputId": "d553dad6-3df0-40dd-9de6-06997f3a123d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/tmp/tmpzlhfafkp\n",
            "total 16\n",
            "drwx------  4 root root 4096 Apr 10 21:05 .\n",
            "drwxrwxrwt  1 root root 4096 Apr 10 21:07 ..\n",
            "drwxr-xr-x  4 root root 4096 Apr 10 21:02 duckietown_object_detection_dataset\n",
            "drwxr-xr-x 11 root root 4096 Apr 10 21:07 yolov5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# We now inform the training process of the format and location of our dataset"
      ],
      "metadata": {
        "id": "g5iilV-e76YN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ./yolov5/data/duckietown.yaml\n",
        "\n",
        "# train and val data as 1) directory: path/images/, 2) file: path/images.txt, or 3) list: [path1/images/, path2/images/]\n",
        "train: ../duckietown_object_detection_dataset/train\n",
        "val: ../duckietown_object_detection_dataset/val\n",
        "\n",
        "# number of classes\n",
        "nc: 4\n",
        "\n",
        "# class names\n",
        "names: [ 'duckie', 'cone', 'truck', 'bus' ]"
      ],
      "metadata": {
        "id": "7u3D124u8Flw",
        "outputId": "aae5f90a-f9ce-411b-af57-0ca26fcc0c1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing ./yolov5/data/duckietown.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -la yolov5"
      ],
      "metadata": {
        "id": "wRvIwCLCjKON",
        "outputId": "7d7537ee-b752-4fef-8598-8b00e6372a4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 4296\n",
            "drwxr-xr-x 11 root root    4096 Apr 10 21:07 .\n",
            "drwx------  4 root root    4096 Apr 10 21:05 ..\n",
            "-rw-r--r--  1 root root    7830 Apr 10 21:05 benchmarks.py\n",
            "drwxr-xr-x  2 root root    4096 Apr 10 21:05 classify\n",
            "-rw-r--r--  1 root root    4994 Apr 10 21:05 CONTRIBUTING.md\n",
            "drwxr-xr-x  5 root root    4096 Apr 10 21:05 data\n",
            "-rw-r--r--  1 root root   14083 Apr 10 21:05 detect.py\n",
            "-rw-r--r--  1 root root    3701 Apr 10 21:05 .dockerignore\n",
            "-rw-r--r--  1 root root   31551 Apr 10 21:05 export.py\n",
            "drwxr-xr-x  8 root root    4096 Apr 10 21:07 .git\n",
            "-rw-r--r--  1 root root      75 Apr 10 21:05 .gitattributes\n",
            "drwxr-xr-x  4 root root    4096 Apr 10 21:05 .github\n",
            "-rwxr-xr-x  1 root root    3982 Apr 10 21:05 .gitignore\n",
            "-rw-r--r--  1 root root    7711 Apr 10 21:05 hubconf.py\n",
            "-rw-r--r--  1 root root   35127 Apr 10 21:05 LICENSE\n",
            "drwxr-xr-x  5 root root    4096 Apr 10 21:06 models\n",
            "-rw-r--r--  1 root root    1554 Apr 10 21:05 .pre-commit-config.yaml\n",
            "drwxr-xr-x  2 root root    4096 Apr 10 21:06 __pycache__\n",
            "-rw-r--r--  1 root root   37340 Apr 10 21:05 README.md\n",
            "-rw-r--r--  1 root root    1541 Apr 10 21:05 requirements.txt\n",
            "drwxr-xr-x  3 root root    4096 Apr 10 21:07 runs\n",
            "drwxr-xr-x  2 root root    4096 Apr 10 21:05 segment\n",
            "-rw-r--r--  1 root root    1686 Apr 10 21:05 setup.cfg\n",
            "-rw-r--r--  1 root root   33528 Apr 10 21:05 train.py\n",
            "-rw-r--r--  1 root root   53842 Apr 10 21:05 tutorial.ipynb\n",
            "drwxr-xr-x  9 root root    4096 Apr 10 21:06 utils\n",
            "-rw-r--r--  1 root root   20282 Apr 10 21:05 val.py\n",
            "-rw-r--r--  1 root root 4062133 Apr 10 21:07 yolov5n.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CalmQI9Ypx5v"
      },
      "source": [
        "# And we're ready to train! This step will take about 5 minutes.\n",
        "\n",
        "Notice that we're only training for 10 epochs. That's probably not enough!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -la yolov5\n"
      ],
      "metadata": {
        "id": "Hb_TXO3-l_WM",
        "outputId": "93ec7b85-83d8-4457-8550-0a25d34a805f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 4296\n",
            "drwxr-xr-x 11 root root    4096 Apr 10 21:07 .\n",
            "drwx------  4 root root    4096 Apr 10 21:05 ..\n",
            "-rw-r--r--  1 root root    7830 Apr 10 21:05 benchmarks.py\n",
            "drwxr-xr-x  2 root root    4096 Apr 10 21:05 classify\n",
            "-rw-r--r--  1 root root    4994 Apr 10 21:05 CONTRIBUTING.md\n",
            "drwxr-xr-x  5 root root    4096 Apr 10 21:05 data\n",
            "-rw-r--r--  1 root root   14083 Apr 10 21:05 detect.py\n",
            "-rw-r--r--  1 root root    3701 Apr 10 21:05 .dockerignore\n",
            "-rw-r--r--  1 root root   31551 Apr 10 21:05 export.py\n",
            "drwxr-xr-x  8 root root    4096 Apr 10 21:07 .git\n",
            "-rw-r--r--  1 root root      75 Apr 10 21:05 .gitattributes\n",
            "drwxr-xr-x  4 root root    4096 Apr 10 21:05 .github\n",
            "-rwxr-xr-x  1 root root    3982 Apr 10 21:05 .gitignore\n",
            "-rw-r--r--  1 root root    7711 Apr 10 21:05 hubconf.py\n",
            "-rw-r--r--  1 root root   35127 Apr 10 21:05 LICENSE\n",
            "drwxr-xr-x  5 root root    4096 Apr 10 21:06 models\n",
            "-rw-r--r--  1 root root    1554 Apr 10 21:05 .pre-commit-config.yaml\n",
            "drwxr-xr-x  2 root root    4096 Apr 10 21:06 __pycache__\n",
            "-rw-r--r--  1 root root   37340 Apr 10 21:05 README.md\n",
            "-rw-r--r--  1 root root    1541 Apr 10 21:05 requirements.txt\n",
            "drwxr-xr-x  3 root root    4096 Apr 10 21:07 runs\n",
            "drwxr-xr-x  2 root root    4096 Apr 10 21:05 segment\n",
            "-rw-r--r--  1 root root    1686 Apr 10 21:05 setup.cfg\n",
            "-rw-r--r--  1 root root   33528 Apr 10 21:05 train.py\n",
            "-rw-r--r--  1 root root   53842 Apr 10 21:05 tutorial.ipynb\n",
            "drwxr-xr-x  9 root root    4096 Apr 10 21:06 utils\n",
            "-rw-r--r--  1 root root   20282 Apr 10 21:05 val.py\n",
            "-rw-r--r--  1 root root 4062133 Apr 10 21:07 yolov5n.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kss7Oid6OkAv",
        "outputId": "549f2dff-a66b-4546-9d99-0f6b96e0b49e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!cd yolov5 && python3 train.py --cfg ./models/yolov5n.yaml --img 416 --batch 32 --epochs 10 --data duckietown.yaml --weights yolov5n.pt"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-10 21:21:42.495806: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1744320102.516062    6867 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1744320102.522221    6867 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-10 21:21:42.543311: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5n.pt, cfg=./models/yolov5n.yaml, data=duckietown.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=10, batch_size=32, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ YOLOv5 is out of date by 411 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
            "YOLOv5 🚀 v7.0-0-g915bbf29 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/tmpzlhfafkp/yolov5/train.py\", line 633, in <module>\n",
            "    main(opt)\n",
            "  File \"/tmp/tmpzlhfafkp/yolov5/train.py\", line 527, in main\n",
            "    train(opt.hyp, opt, device, callbacks)\n",
            "  File \"/tmp/tmpzlhfafkp/yolov5/train.py\", line 123, in train\n",
            "    ckpt = torch.load(weights, map_location='cpu')  # load checkpoint to CPU to avoid CUDA memory leak\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/serialization.py\", line 1470, in load\n",
            "    raise pickle.UnpicklingError(_get_wo_message(str(e))) from None\n",
            "_pickle.UnpicklingError: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n",
            "\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n",
            "\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n",
            "\tWeightsUnpickler error: Unsupported global: GLOBAL models.yolo.Model was not an allowed global by default. Please use `torch.serialization.add_safe_globals([Model])` or the `torch.serialization.safe_globals([Model])` context manager to allowlist this global if you trust this class/function.\n",
            "\n",
            "Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ln5UhhLPl02Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# List only directories that start with \"exp\"\n",
        "all_exps = [exp for exp in os.listdir(\"yolov5/runs/train\") if exp.startswith(\"exp\")]\n",
        "\n",
        "# Function to extract the experiment number (assuming \"exp\" alone means 0)\n",
        "def extract_exp_number(exp_name):\n",
        "    if exp_name == \"exp\":\n",
        "        return 0\n",
        "    try:\n",
        "        # Remove the literal \"exp\" prefix and convert the rest to an integer.\n",
        "        return int(exp_name.replace(\"exp\", \"\"))\n",
        "    except ValueError:\n",
        "        return -1\n",
        "\n",
        "# Build a list of experiment folders that actually have the best.pt file.\n",
        "valid_exps = []\n",
        "for exp in all_exps:\n",
        "    best_path = os.path.join(\"yolov5\", \"runs\", \"train\", exp, \"weights\", \"best.pt\")\n",
        "    if os.path.exists(best_path):\n",
        "        valid_exps.append(exp)\n",
        "    else:\n",
        "        print(f\"Skipping {exp}: No weights file found at {best_path}\")\n",
        "\n",
        "if not valid_exps:\n",
        "    print(\"Error: No experiment folder with a valid 'best.pt' found.\")\n",
        "else:\n",
        "    # Extract numbers for the valid experiments and choose the one with the highest number.\n",
        "    exp_numbers = [extract_exp_number(exp) for exp in valid_exps]\n",
        "    latest_exp_index = np.argmax(exp_numbers)\n",
        "    latest_exp = valid_exps[latest_exp_index]\n",
        "    print(f\"Latest valid exp is {latest_exp}\")\n",
        "\n",
        "    # Copy the file from the chosen experiment folder.\n",
        "    src_path = os.path.join(\"yolov5\", \"runs\", \"train\", latest_exp, \"weights\", \"best.pt\")\n",
        "    dest_path = os.path.join(\"yolov5\", \"best.pt\")\n",
        "    os.system(f\"cp {src_path} {dest_path}\")\n",
        "    print(f\"Marked the model from the latest run ({latest_exp}) as {dest_path}.\")\n"
      ],
      "metadata": {
        "id": "R0i2zo8h5KN_",
        "outputId": "9959a54a-4f34-44eb-8f0d-2b6fefe3123b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping exp: No weights file found at yolov5/runs/train/exp/weights/best.pt\n",
            "Error: No experiment folder with a valid 'best.pt' found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "all_exps = os.listdir(\"yolov5/runs/train\")\n",
        "all_exps_filtered = map(lambda x: int(x.replace(\"exp\", \"1\")), filter(lambda x: x.startswith(\"exp\"), all_exps))\n",
        "all_exps_filtered = np.array(list(all_exps))\n",
        "latest_exp_index = np.argmax(all_exps)\n",
        "latest_exp = all_exps[latest_exp_index]\n",
        "print(f\"Latest exp is {latest_exp}\")\n",
        "\n",
        "prun(f\"cp yolov5/runs/train/{latest_exp}/weights/best.pt yolov5/best.pt\")\n",
        "print(f\"Marked the model from the latest run ({latest_exp}) as yolov5/best.pt.\")"
      ],
      "metadata": {
        "id": "b5jSQ4XubFqH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43e80a69-6451-4050-d7b8-c81c22bc0c0a"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Latest exp is exp\n",
            "cp: cannot stat 'yolov5/runs/train/exp/weights/best.pt': No such file or directory\n",
            "\n",
            "Marked the model from the latest run (exp) as yolov5/best.pt.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz2PZ7d0qPt0"
      },
      "source": [
        "# Next, we can upload your model to Duckietown's cloud!\n",
        "\n",
        "We will need our token to access our personal cloud space."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Fill in the duckietown token here\n",
        "YOUR_DT_TOKEN = \"dt2-Npc1n4fne9txYPw32KUJ9FoCkBX4dVpPjMSdZDjNpZrCusVAmNUoaW6SSVJBNUqNw6SVUhN4rmmzSfXLyr-43dzqWFnWd8KBa1yev1g3UKnzVxZkkTbfQzdX1DLcP3mgeLMBYDBxmfeatgZ4poxsV\""
      ],
      "metadata": {
        "id": "hl-HhnrFtKnp"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we chose the location of the trained model on disk and its name once uploaded to our cloud space. You should not change these values, or the robots will not be able to find the model to download."
      ],
      "metadata": {
        "id": "PCd7RrjLc64Z"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bNXEgAFpRIH",
        "outputId": "3f387813-c24d-4835-9466-ef40f5a728cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0, './yolov5')\n",
        "\n",
        "# DO NOT CHANGE THESE\n",
        "model_name = \"yolov5n\"\n",
        "model_local_path = \"./yolov5/best.pt\"\n",
        "model_remote_path = f\"courses/mooc/objdet/data/nn_models/{model_name}.pt\"\n",
        "\n",
        "# install DCSS client\n",
        "!pip3 install dt-data-api"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dt-data-api\n",
            "  Downloading dt-data-api-2.1.0.tar.gz (12 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from dt-data-api) (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from dt-data-api) (4.13.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from dt-data-api) (5.3.1)\n",
            "Collecting dt-authentication (from dt-data-api)\n",
            "  Downloading dt-authentication-2.2.0.tar.gz (9.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->dt-data-api) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->dt-data-api) (4.13.1)\n",
            "Collecting base58 (from dt-authentication->dt-data-api)\n",
            "  Downloading base58-2.1.1-py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting ecdsa (from dt-authentication->dt-data-api)\n",
            "  Downloading ecdsa-0.19.1-py2.py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->dt-data-api) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->dt-data-api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->dt-data-api) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->dt-data-api) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from ecdsa->dt-authentication->dt-data-api) (1.17.0)\n",
            "Downloading base58-2.1.1-py3-none-any.whl (5.6 kB)\n",
            "Downloading ecdsa-0.19.1-py2.py3-none-any.whl (150 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.6/150.6 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: dt-data-api, dt-authentication\n",
            "  Building wheel for dt-data-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dt-data-api: filename=dt_data_api-2.1.0-py3-none-any.whl size=14363 sha256=b887139473b7d15f2742c8bf30c2c9314757feb9e1c448c90b0e2a7658507658\n",
            "  Stored in directory: /root/.cache/pip/wheels/f9/b5/60/d35f7f09040a1b33db975be4f28603b344bf1e9d2bddef6ac7\n",
            "  Building wheel for dt-authentication (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dt-authentication: filename=dt_authentication-2.2.0-py3-none-any.whl size=10095 sha256=93d8885a639af7c118dcbee636b886f00b0a609bd12f3c0f4ba2bc533dbc9561\n",
            "  Stored in directory: /root/.cache/pip/wheels/f7/d5/e7/985e33386d61f6b4027fe7f9a2afec5a491972b3948b71a425\n",
            "Successfully built dt-data-api dt-authentication\n",
            "Installing collected packages: ecdsa, base58, dt-authentication, dt-data-api\n",
            "Successfully installed base58-2.1.1 dt-authentication-2.2.0 dt-data-api-2.1.0 ecdsa-0.19.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now open a pointer to our cloud space and upload the model."
      ],
      "metadata": {
        "id": "B8DYodvDdQKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists(model_local_path):\n",
        "    print(f\"File not found: {model_local_path}\")\n",
        "else:\n",
        "    print(f\"File found at: {model_local_path}\")"
      ],
      "metadata": {
        "id": "p7PQ1_Bs4ESo",
        "outputId": "341145f2-5a01-4735-fe06-7dd1067df924",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File not found: ./yolov5/best.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from dt_data_api import DataClient, Storage\n",
        "\n",
        "# open a pointer to our personal duckietown cloud space\n",
        "client = DataClient(\"dt2-Npc1n4fne9txYPw32KUJ9FoCkBX4dVpPjMSdZDjNpZrCusVAmNUoaW6SSVJBNUqNw6SVUhN4rmmzSfXLyr-43dzqWFnWd8KBa1yev1g3UKnzVxZkkTbfQzdX1DLcP3mgeLMBYDBxmfeatgZ4poxsV\")\n",
        "storage = client.storage(\"user\")\n",
        "\n",
        "# upload model\n",
        "upload = storage.upload(model_local_path, model_remote_path)\n",
        "upload.join()"
      ],
      "metadata": {
        "id": "NAU4dTNJVkyx",
        "outputId": "6f0f4388-7f03-471c-e9da-4c271e24a71e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The file /tmp/tmpx5r8u6t2/yolov5/best.pt does not exist.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-7953829abe6e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# upload model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mupload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_local_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_remote_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mupload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/dt_data_api/storage.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(self, source, destination, length)\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"The file {file_path} does not exist.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0msource_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The file /tmp/tmpx5r8u6t2/yolov5/best.pt does not exist."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUVJ5BfBGq7F"
      },
      "source": [
        "# Done!\n",
        "\n",
        "We're done training! You can now close this tab and go back to the `Training` notebook"
      ]
    }
  ]
}