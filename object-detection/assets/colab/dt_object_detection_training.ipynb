{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mIJd6b6pbsk"
      },
      "source": [
        "# First, let us set up a few dependencies\n",
        "\n",
        "Don't forget to switch to a GPU-enabled colab runtime!\n",
        "\n",
        "```\n",
        "Runtime -> Change Runtime Type -> GPU\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E2APl4pnbAa"
      },
      "source": [
        "import os\n",
        "import contextlib\n",
        "@contextlib.contextmanager\n",
        "def directory(name):\n",
        "  ret = os.getcwd()\n",
        "  os.chdir(name)\n",
        "  yield None\n",
        "  os.chdir(ret)\n",
        "\n",
        "import subprocess\n",
        "def run(input, exception_on_failure=False):\n",
        "  try:\n",
        "    program_output = subprocess.check_output(f\"{input}\", shell=True, universal_newlines=True, stderr=subprocess.STDOUT)\n",
        "  except Exception as e:\n",
        "    if exception_on_failure:\n",
        "      raise e\n",
        "    program_output = e.output\n",
        "\n",
        "    return program_output\n",
        "def prun(input, exception_on_failure=False):\n",
        "  x = run(input, exception_on_failure)\n",
        "  print(x)\n",
        "  return x"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6gJLjcipgNw"
      },
      "source": [
        "# This mounts your google drive to this notebook. You might have to change the path to fit with your dataset folder inside your drive.\n",
        "\n",
        "Read the instruction output by the cell bellow carefully!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a temporary workspace\n",
        "import tempfile\n",
        "\n",
        "\n",
        "SESSION_WORKSPACE = tempfile.mkdtemp()\n",
        "print(f\"Session workspace created at: {SESSION_WORKSPACE}\")"
      ],
      "metadata": {
        "id": "shRmyOAbatwZ",
        "outputId": "f232982b-c7ac-4ea4-a2d5-702cb71c7de1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Session workspace created at: /tmp/tmp3lvgaiml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "DRIVE_PATH = \"/content/drive/My Drive\""
      ],
      "metadata": {
        "id": "Iod0c4KF_Vxo",
        "outputId": "112702e1-8507-4f4e-bc82-41eb7d69c5ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip the dataset\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "\n",
        "DATASET_DIR_NAME = \"duckietown_object_detection_dataset\"\n",
        "DATASET_ZIP_NAME = f\"{DATASET_DIR_NAME}.zip\"\n",
        "DATASET_DIR_PATH = os.path.join(SESSION_WORKSPACE, DATASET_DIR_NAME)\n",
        "TRAIN_DIR = \"train\"\n",
        "VALIDATION_DIR = \"val\"\n",
        "IMAGES_DIR = \"images\"\n",
        "LABELS_DIR = \"labels\"\n",
        "\n",
        "\n",
        "def show_info(base_path: str):\n",
        "  for l1 in [TRAIN_DIR, VALIDATION_DIR]:\n",
        "    for l2 in [IMAGES_DIR, LABELS_DIR]:\n",
        "      p = os.path.join(base_path, l1, l2)\n",
        "      print(f\"#Files in {l1}/{l2}: {len(os.listdir(p))}\")\n",
        "\n",
        "\n",
        "def unzip_dataset():\n",
        "  # check zipped file\n",
        "  zip_path = os.path.join(DRIVE_PATH, DATASET_ZIP_NAME)\n",
        "  assert os.path.exists(zip_path), f\"No zipped dataset found at {zip_path}! Abort!\"\n",
        "\n",
        "  # unzip the data\n",
        "  print(\"Unpacking zipped data...\")\n",
        "  shutil.unpack_archive(zip_path, DATASET_DIR_PATH)\n",
        "  print(f\"Zipped dataset unpacked to {DATASET_DIR_PATH}\")\n",
        "\n",
        "  # show some info\n",
        "  show_info(DATASET_DIR_PATH)\n",
        "\n",
        "\n",
        "unzip_dataset()"
      ],
      "metadata": {
        "id": "qhdlb1osbf_a",
        "outputId": "7533e469-984f-4ee4-edb3-e756297642de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unpacking zipped data...\n",
            "Zipped dataset unpacked to /tmp/tmp3lvgaiml/duckietown_object_detection_dataset\n",
            "#Files in train/images: 804\n",
            "#Files in train/labels: 804\n",
            "#Files in val/images: 202\n",
            "#Files in val/labels: 202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change  working directory to the session workspace\n",
        "os.chdir(SESSION_WORKSPACE)\n",
        "print(f\"PWD: {os.getcwd()}\")\n",
        "\n",
        "# install pytorch and torchvision\n",
        "!pip3 install torch==1.13.0 torchvision\n",
        "#!pip3 install torch==1.13.0 torchvision==0.14.0"
      ],
      "metadata": {
        "id": "xpWozMbUeFZA",
        "outputId": "5ca27bf6-471f-4a6b-daeb-0bf35993dfa4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PWD: /tmp/tmp3lvgaiml\n",
            "Collecting torch==1.13.0\n",
            "  Using cached torch-1.13.0-cp311-cp311-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.15.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==1.13.0) (4.13.1)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch==1.13.0) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.11/dist-packages (from torch==1.13.0) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.11/dist-packages (from torch==1.13.0) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch==1.13.0) (11.7.99)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0) (75.2.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0) (0.45.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.32.3)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision\n",
            "  Using cached torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "  Using cached torchvision-0.20.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "  Using cached torchvision-0.20.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "  Using cached torchvision-0.19.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
            "  Using cached torchvision-0.19.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
            "  Using cached torchvision-0.18.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "  Using cached torchvision-0.18.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "INFO: pip is still looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "  Using cached torchvision-0.17.2-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "  Using cached torchvision-0.17.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "  Using cached torchvision-0.17.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "  Using cached torchvision-0.16.2-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "  Using cached torchvision-0.16.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Using cached torchvision-0.16.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "  Using cached torchvision-0.15.2-cp311-cp311-manylinux1_x86_64.whl.metadata (11 kB)\n",
            "\u001b[31mERROR: Cannot install torch==1.13.0, torchvision==0.15.1, torchvision==0.15.2, torchvision==0.16.0, torchvision==0.16.1, torchvision==0.16.2, torchvision==0.17.0, torchvision==0.17.1, torchvision==0.17.2, torchvision==0.18.0, torchvision==0.18.1, torchvision==0.19.0, torchvision==0.19.1, torchvision==0.20.0, torchvision==0.20.1 and torchvision==0.21.0 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "The conflict is caused by:\n",
            "    The user requested torch==1.13.0\n",
            "    torchvision 0.15.1 depends on torch==2.0.0\n",
            "    The user requested torch==1.13.0\n",
            "    torchvision 0.21.0 depends on torch==2.6.0\n",
            "    The user requested torch==1.13.0\n",
            "    torchvision 0.20.1 depends on torch==2.5.1\n",
            "    The user requested torch==1.13.0\n",
            "    torchvision 0.20.0 depends on torch==2.5.0\n",
            "    The user requested torch==1.13.0\n",
            "    torchvision 0.19.1 depends on torch==2.4.1\n",
            "    The user requested torch==1.13.0\n",
            "    torchvision 0.19.0 depends on torch==2.4.0\n",
            "    The user requested torch==1.13.0\n",
            "    torchvision 0.18.1 depends on torch==2.3.1\n",
            "    The user requested torch==1.13.0\n",
            "    torchvision 0.18.0 depends on torch==2.3.0\n",
            "    The user requested torch==1.13.0\n",
            "    torchvision 0.17.2 depends on torch==2.2.2\n",
            "    The user requested torch==1.13.0\n",
            "    torchvision 0.17.1 depends on torch==2.2.1\n",
            "    The user requested torch==1.13.0\n",
            "    torchvision 0.17.0 depends on torch==2.2.0\n",
            "    The user requested torch==1.13.0\n",
            "    torchvision 0.16.2 depends on torch==2.1.2\n",
            "    The user requested torch==1.13.0\n",
            "    torchvision 0.16.1 depends on torch==2.1.1\n",
            "    The user requested torch==1.13.0\n",
            "    torchvision 0.16.0 depends on torch==2.1.0\n",
            "    The user requested torch==1.13.0\n",
            "    torchvision 0.15.2 depends on torch==2.0.1\n",
            "\n",
            "To fix this you could try to:\n",
            "1. loosen the range of package versions you've specified\n",
            "2. remove package versions to allow pip to attempt to solve the dependency conflict\n",
            "\n",
            "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc4VMcwmpr84"
      },
      "source": [
        "# Next, we will clone Yolov5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8L68QAeZF9G",
        "outputId": "93bfea8b-6bf8-4d0a-bab9-d8f4eb7facfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!rm -rf ./yolov5\n",
        "!git clone https://github.com/ultralytics/yolov5.git -b v7.0\n",
        "!cd yolov5 && pip3 install -r requirements.txt"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 17372, done.\u001b[K\n",
            "remote: Counting objects: 100% (59/59), done.\u001b[K\n",
            "remote: Compressing objects: 100% (39/39), done.\u001b[K\n",
            "remote: Total 17372 (delta 42), reused 20 (delta 20), pack-reused 17313 (from 3)\u001b[K\n",
            "Receiving objects: 100% (17372/17372), 16.24 MiB | 14.28 MiB/s, done.\n",
            "Resolving deltas: 100% (11904/11904), done.\n",
            "Note: switching to '915bbf294bb74c859f0b41f1c23bc395014ea679'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by switching back to a branch.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -c with the switch command. Example:\n",
            "\n",
            "  git switch -c <new-branch-name>\n",
            "\n",
            "Or undo this operation with:\n",
            "\n",
            "  git switch -\n",
            "\n",
            "Turn off this advice by setting config variable advice.detachedHead to false\n",
            "\n",
            "Requirement already satisfied: gitpython in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (3.1.44)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (7.34.0)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (2.0.2)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (4.11.0.86)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (11.1.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (5.9.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (1.14.1)\n",
            "Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (2.0.0)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 17)) (0.15.1)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 18)) (4.67.1)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 22)) (2.18.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 27)) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 28)) (0.13.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython->-r requirements.txt (line 5)) (4.0.12)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython->-r requirements.txt (line 6)) (75.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython->-r requirements.txt (line 6)) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython->-r requirements.txt (line 6)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython->-r requirements.txt (line 6)) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython->-r requirements.txt (line 6)) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython->-r requirements.txt (line 6)) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython->-r requirements.txt (line 6)) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython->-r requirements.txt (line 6)) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython->-r requirements.txt (line 6)) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython->-r requirements.txt (line 6)) (4.9.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 7)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 7)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 7)) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 7)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 7)) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 7)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 7)) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->-r requirements.txt (line 13)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->-r requirements.txt (line 13)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->-r requirements.txt (line 13)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->-r requirements.txt (line 13)) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (4.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (2.0.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.7.0->-r requirements.txt (line 16)) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch>=1.7.0->-r requirements.txt (line 16)) (3.31.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch>=1.7.0->-r requirements.txt (line 16)) (18.1.8)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (5.29.4)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (3.1.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2025.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython->-r requirements.txt (line 5)) (5.0.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython->-r requirements.txt (line 6)) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython->-r requirements.txt (line 6)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->-r requirements.txt (line 6)) (0.2.13)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->-r requirements.txt (line 22)) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.7.0->-r requirements.txt (line 16)) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# We now inform the training process of the format and location of our dataset"
      ],
      "metadata": {
        "id": "g5iilV-e76YN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ./yolov5/data/duckietown.yaml\n",
        "\n",
        "# train and val data as 1) directory: path/images/, 2) file: path/images.txt, or 3) list: [path1/images/, path2/images/]\n",
        "train: ../duckietown_object_detection_dataset/train\n",
        "val: ../duckietown_object_detection_dataset/val\n",
        "\n",
        "# number of classes\n",
        "nc: 4\n",
        "\n",
        "# class names\n",
        "names: [ 'duckie', 'cone', 'truck', 'bus' ]"
      ],
      "metadata": {
        "id": "7u3D124u8Flw",
        "outputId": "6f9070aa-39f9-4d77-96a7-2b95326ef63a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing ./yolov5/data/duckietown.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CalmQI9Ypx5v"
      },
      "source": [
        "# And we're ready to train! This step will take about 5 minutes.\n",
        "\n",
        "Notice that we're only training for 10 epochs. That's probably not enough!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kss7Oid6OkAv",
        "outputId": "215f8bcf-936b-4322-978b-7d55f741c6d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!cd yolov5 && python3 train.py --cfg ./models/yolov5n.yaml --img 416 --batch 32 --epochs 10 --data duckietown.yaml --weights yolov5n.pt"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pybind11\n",
            "  Downloading pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Downloading pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/243.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m243.3/243.3 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pybind11\n",
            "Successfully installed pybind11-2.13.6\n",
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"/tmp/tmp3lvgaiml/yolov5/train.py\", line 42, in <module>\n",
            "    import val as validate  # for end-of-epoch mAP\n",
            "  File \"/tmp/tmp3lvgaiml/yolov5/val.py\", line 38, in <module>\n",
            "    from models.common import DetectMultiBackend\n",
            "  File \"/tmp/tmp3lvgaiml/yolov5/models/common.py\", line 29, in <module>\n",
            "    from utils.dataloaders import exif_transpose, letterbox\n",
            "  File \"/tmp/tmp3lvgaiml/yolov5/utils/dataloaders.py\", line 25, in <module>\n",
            "    import torchvision\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/__init__.py\", line 6, in <module>\n",
            "    from torchvision import datasets, io, models, ops, transforms, utils\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/models/__init__.py\", line 17, in <module>\n",
            "    from . import detection, optical_flow, quantization, segmentation, video\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/models/detection/__init__.py\", line 1, in <module>\n",
            "    from .faster_rcnn import *\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/models/detection/faster_rcnn.py\", line 16, in <module>\n",
            "    from .anchor_utils import AnchorGenerator\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/models/detection/anchor_utils.py\", line 10, in <module>\n",
            "    class AnchorGenerator(nn.Module):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/models/detection/anchor_utils.py\", line 63, in AnchorGenerator\n",
            "    device: torch.device = torch.device(\"cpu\"),\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/detection/anchor_utils.py:63: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  device: torch.device = torch.device(\"cpu\"),\n",
            "2025-04-11 16:10:28.500268: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1744387828.520916   15263 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1744387828.527095   15263 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-11 16:10:28.548123: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5n.pt, cfg=./models/yolov5n.yaml, data=duckietown.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=10, batch_size=32, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 411 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
            "YOLOv5 üöÄ v7.0-0-g915bbf29 Python-3.11.12 torch-2.0.0+cu117 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 üöÄ in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Overriding model.yaml nc=80 with nc=4\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      1760  models.common.Conv                      [3, 16, 6, 2, 2]              \n",
            "  1                -1  1      4672  models.common.Conv                      [16, 32, 3, 2]                \n",
            "  2                -1  1      4800  models.common.C3                        [32, 32, 1]                   \n",
            "  3                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  4                -1  2     29184  models.common.C3                        [64, 64, 2]                   \n",
            "  5                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  6                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  7                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  8                -1  1    296448  models.common.C3                        [256, 256, 1]                 \n",
            "  9                -1  1    164608  models.common.SPPF                      [256, 256, 5]                 \n",
            " 10                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 14                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     22912  models.common.C3                        [128, 64, 1, False]           \n",
            " 18                -1  1     36992  models.common.Conv                      [64, 64, 3, 2]                \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1     74496  models.common.C3                        [128, 128, 1, False]          \n",
            " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 24      [17, 20, 23]  1     12177  models.yolo.Detect                      [4, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [64, 128, 256]]\n",
            "YOLOv5n summary: 214 layers, 1769329 parameters, 1769329 gradients, 4.2 GFLOPs\n",
            "\n",
            "Transferred 342/349 items from yolov5n.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks failed ‚ùå, disabling Automatic Mixed Precision. See https://github.com/ultralytics/yolov5/issues/7908\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0m1 validation error for InitSchema\n",
            "size\n",
            "  Field required [type=missing, input_value={'scale': (0.8, 1.0), 'ra...'mask_interpolation': 0}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /tmp/tmp3lvgaiml/duckietown_object_detection_dataset/train/labels.cache... 804 images, 0 backgrounds, 0 corrupt: 100% 804/804 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /tmp/tmp3lvgaiml/duckietown_object_detection_dataset/val/labels.cache... 202 images, 0 backgrounds, 0 corrupt: 100% 202/202 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.88 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
            "Plotting labels to runs/train/exp3/labels.jpg... \n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/tmp3lvgaiml/yolov5/train.py\", line 633, in <module>\n",
            "    main(opt)\n",
            "  File \"/tmp/tmp3lvgaiml/yolov5/train.py\", line 527, in main\n",
            "    train(opt.hyp, opt, device, callbacks)\n",
            "  File \"/tmp/tmp3lvgaiml/yolov5/train.py\", line 240, in train\n",
            "    model.class_weights = labels_to_class_weights(dataset.labels, nc).to(device) * nc  # attach class weights\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/tmp3lvgaiml/yolov5/utils/general.py\", line 728, in labels_to_class_weights\n",
            "    return torch.from_numpy(weights).float()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Numpy is not available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "all_exps = os.listdir(\"yolov5/runs/train\")\n",
        "all_exps_filtered = map(lambda x: int(x.replace(\"exp\", \"1\")), filter(lambda x: x.startswith(\"exp\"), all_exps))\n",
        "all_exps_filtered = np.array(list(all_exps))\n",
        "latest_exp_index = np.argmax(all_exps)\n",
        "latest_exp = all_exps[latest_exp_index]\n",
        "print(f\"Latest exp is {latest_exp}\")\n",
        "\n",
        "prun(f\"cp yolov5/runs/train/{latest_exp}/weights/best.pt yolov5/best.pt\")\n",
        "print(f\"Marked the model from the latest run ({latest_exp}) as yolov5/best.pt.\")"
      ],
      "metadata": {
        "id": "b5jSQ4XubFqH",
        "outputId": "fefe1371-8c64-4003-ca25-e850f9d95dd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Latest exp is exp3\n",
            "cp: cannot stat 'yolov5/runs/train/exp3/weights/best.pt': No such file or directory\n",
            "\n",
            "Marked the model from the latest run (exp3) as yolov5/best.pt.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz2PZ7d0qPt0"
      },
      "source": [
        "# Next, we can upload your model to Duckietown's cloud!\n",
        "\n",
        "We will need our token to access our personal cloud space."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Fill in the duckietown token here\n",
        "YOUR_DT_TOKEN = \"dt1-DHcEZkb4F7AbsdjUR3SvZud36MzrK5MzKAbLuoVeyvm5NYuJ-43dzqWFnWd8KBa1yev1g3UKnzVxZkkTbfbh2S93NeJvE8jnsM7va9CsaFWCeHabJ8p\""
      ],
      "metadata": {
        "id": "hl-HhnrFtKnp"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we chose the location of the trained model on disk and its name once uploaded to our cloud space. You should not change these values, or the robots will not be able to find the model to download."
      ],
      "metadata": {
        "id": "PCd7RrjLc64Z"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bNXEgAFpRIH",
        "outputId": "5f24e743-0e62-408f-a4d0-c5730c0d99e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0, './yolov5')\n",
        "\n",
        "# DO NOT CHANGE THESE\n",
        "model_name = \"yolov5n\"\n",
        "model_local_path = \"./yolov5/best.pt\"\n",
        "model_remote_path = f\"courses/mooc/objdet/data/nn_models/{model_name}.pt\"\n",
        "\n",
        "# install DCSS client\n",
        "!pip3 install dt-data-api"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dt-data-api in /usr/local/lib/python3.11/dist-packages (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from dt-data-api) (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from dt-data-api) (4.13.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from dt-data-api) (5.3.1)\n",
            "Requirement already satisfied: dt-authentication in /usr/local/lib/python3.11/dist-packages (from dt-data-api) (2.2.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->dt-data-api) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->dt-data-api) (4.13.1)\n",
            "Requirement already satisfied: base58 in /usr/local/lib/python3.11/dist-packages (from dt-authentication->dt-data-api) (2.1.1)\n",
            "Requirement already satisfied: ecdsa in /usr/local/lib/python3.11/dist-packages (from dt-authentication->dt-data-api) (0.19.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->dt-data-api) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->dt-data-api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->dt-data-api) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->dt-data-api) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from ecdsa->dt-authentication->dt-data-api) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now open a pointer to our cloud space and upload the model."
      ],
      "metadata": {
        "id": "B8DYodvDdQKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from dt_data_api import DataClient, Storage\n",
        "\n",
        "# open a pointer to our personal duckietown cloud space\n",
        "client = DataClient(YOUR_DT_TOKEN)\n",
        "storage = client.storage(\"user\")\n",
        "\n",
        "# upload model\n",
        "upload = storage.upload(model_local_path, model_remote_path)\n",
        "upload.join()"
      ],
      "metadata": {
        "id": "NAU4dTNJVkyx",
        "outputId": "d7bac9f2-56f9-4a17-df0a-144f08b12ec7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The file /tmp/tmp3lvgaiml/yolov5/best.pt does not exist.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-8a773fbdffef>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# upload model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mupload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_local_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_remote_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mupload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/dt_data_api/storage.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(self, source, destination, length)\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"The file {file_path} does not exist.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0msource_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The file /tmp/tmp3lvgaiml/yolov5/best.pt does not exist."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUVJ5BfBGq7F"
      },
      "source": [
        "# Done!\n",
        "\n",
        "We're done training! You can now close this tab and go back to the `Training` notebook"
      ]
    }
  ]
}